---
layout: post
title:  "小笔记-1"
date:   2020-05-06 10:04:00
categories: DeepLearning
tags: DeepLearning
excerpt: 小笔记-1
---


### softmax与nce区别

[https://www.zhihu.com/question/50043438](https://www.zhihu.com/question/50043438)
[https://carlos9310.github.io/2019/10/15/Approximating-the-Softmax/](https://carlos9310.github.io/2019/10/15/Approximating-the-Softmax/)

通常训练例如word2vec的时候，我们最后用full softmax预测出下一个词，真实的值通常是一小部分context words,也就是一小部分target classes，在非常大的语料库中(通常维度为百万），softmax需要对每一个class  预测出probability，那么类别数非常大的时候，计算量就非常大。


优化：我们可不可以针对这么昂贵的计算 进行优化，不计算所有class的probability，但同时给我们一个合理的loss？ 这里就引入了NCE（Noise-contrastive estimation)：对于每一个训练样本（x, T)，我们训练binary classification，而不是multiclass classification。具体一点，我们对于每个样本，拆分成一个真实的（x,y)pair,另外我们随机产生k个Noise的（x,y）pair,这样我们就可以用来训练处这样的binary classifier。


<img src="/images/memo1/softmax_nce_01.png" width="60%" height="60%">


用概率来表示，这个问题由之前的P(y\|x) 通过x预测所有y，换成了P(x,y)，计算x,y同时存在的概率。


### xgboost

[https://mp.weixin.qq.com/s/lfd7gHGmyY8-cqSnkauc6Q](https://mp.weixin.qq.com/s/lfd7gHGmyY8-cqSnkauc6Q)

XGBoost和GBDT两者都是boosting方法，除了工程实现、解决问题上的一些差异外，最大的不同就是目标函数的定义。

正则项：叶子节点数量、所有节点权重所组成的向量的L2范数

损失函数：泰勒公式二阶展开。只需要求出每一步损失函数的一阶导和二阶导的值，然后最优化目标函数，就可以得到每一步的f

一棵树（f）的生成：贪心法分裂叶子结点（global／local候选切分点）


优化：

 - 稀疏感知：为缺失的稀疏特征选取一个默认的方向

 - 列块并行：CSR（多个列组成一个块）。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个特征的增益计算可以同时进行，这也是 XGBoost 能够实现分布式或者多线程计算的原因。

   XGBoost的并行，指的是特征维度的并行：在训练之前，每个特征按特征值对样本进行预排序，并存储为Block结构，在后面查找特征分割点时可以重复使用，而且特征已经被存储为一个个block结构，那么在寻找每个特征的最佳分割点时，可以利用多线程对每个block并行计算。


优点：

- 精度／灵活性： GBDT 只用到一阶泰勒展开，而 XGBoost 对损失函数进行了二阶泰勒展开。XGBoost 引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数；

- 正则化： XGBoost 在目标函数中加入了正则项，用于控制模型的复杂度。

- Shrinkage（缩减）：XGBoost 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。

- 列抽样： XGBoost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算。

- 缺失值处理： 对于特征的值有缺失的样本，XGBoost 采用的稀疏感知算法可以自动学习出它的分裂方向；

缺点：

 - 预排序过程的空间复杂度过高，不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引。


### Adagrad、Adam

Adagrad:  $$ \theta_{i,t+1} = \theta_{i,t} - \dfrac{\eta}{\sqrt{G_{t} + \epsilon}} \cdot g_{i,t} $$

Adam:  $$ \theta_{t+1} = \theta_{t} - \dfrac{\eta}{\sqrt{\hat{G}\_t} + \epsilon} \hat{m}\_t $$

\begin{align}
m_t &= \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
G_t &= \beta_2 G_{t-1} + (1 - \beta_2) g_t^2 \\
\hat m_t = \dfrac{m_t}{1 - \beta_1} \\
\hat G_t = \dfrac{G_t}{1 - \beta_2}\\
\end{align}


### local sgd、GEO

geo特点：

 - 本地局部更新多轮（降低通信占比）
 - Trainer维护独立参数，更新时考虑与全局的diff（局部最优与全局最优）
 - 全异步多线程全局无锁更新（对比LEGO）（将通信占比在设计上压缩到最低）


### rnn、lstm

### attention

[https://zhuanlan.zhihu.com/p/47282410](https://zhuanlan.zhihu.com/p/47282410)

q 和 k v，一般是 q（当前item id）和 k v（历史item id） 以及 q（句子里的一个词）和k v（句子）

### dqn

在状态$$ s_t $$，大脑 agent 会从可以选择的动作集合 A 中选择一个动作 $$ a_t $$执行。 环境则根据 agent 的动作给 agent 反馈一个 reward $$ r_t $$， 同时 agent 进入一个新的状态 $$ s_t + 1 $$

用一张表存储在各个状态下执行各种动作能够带来的 reward。这个表叫做Q-Table

当 Q-Table 中的状态比较多，可能会导致整个 Q-Table过大。 因此，DQN 被提了出来，通过神经网络来拟合整个 Q-Table。


<img src="/images/rl/5.png" width="60%" height="60%">


DQN中有两个神经网络(NN)一个参数相对固定的网络，我们叫做target-net，用来获取Q-目标(Q-target)的数值, 另外一个叫做eval_net用来获取Q-评估(Q-eval)的数值。（原因是在计算目标值𝑦𝑗时用到了我们需要训练的网络𝑄，之后我们又用目标值𝑦𝑗来更新网络𝑄的参数，这样两者的依赖性太强，不利于算法的收敛）

我们在训练神经网络参数时用到的损失函数(Loss function)，实际上就是q_target 减 q_eval的结果 (loss = q_target- q_eval )。

随机抽取记忆库中的数据进行学习，打乱了经历之间的相关性，使得神经网络更新更有效率。


### ring allreduce


像一张斜着剪的抽纸，抽两圈


N个GPU中的每一个都将发送和接收N-1次scatter-reduce，N-1次allgather。每次，GPU都会发送K / N值，其中K是数组中不同GPU上相加的值总数。因此，传输到每个GPU和从每个GPU传输的数据总量为

$$ 2 * (N - 1) * K / N $$

可以与GPU的数量无关。 

### ssd

省内存，内存可以作为热点cache


rocksdb：分层写／批量flush，写放大，lsm的level=1，或者直接维护一个磁盘上的索引

数据压缩

只有miss数据访问ssd，读不是瓶颈。


### rtti

Runtime Type Information

C++中的指针或引用(Reference)本身的类型，可能与它实际代表(指向或引用)的类型并不一致。有时我们需要将一个多态指针转换为其实际指向对象的类型，就需要知道运行时的类型信息，这就产生了运行时类型识别的要求。

typeid的主要作用就是让用户知道当前的变量是什么类型的，对于内置数据类型以及自定义数据类型都生效.

dynamic_cast操作符，将基类类型的指针或引用安全地转换为其派生类类型的指针或引用。

### 内存优化

消除反向op依赖：反向不一定依赖这个op的所有前向输入 (relu)

inplace：输出复用输入的内存

GC：引用计数。及时释放无用变量

### map reduce

[https://cshihong.github.io/2018/05/11/MapReduce%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/](https://cshihong.github.io/2018/05/11/MapReduce%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/)

### 前中后序遍历

中序

```cpp
   vector<int> inorderTraversal(TreeNode* root) {
        vector<int> ans;
        if (!root) {
            return ans;
        }
        stack<TreeNode*> st;
        TreeNode* p = root;
        while(!st.empty() || p) {
            while(p) {
                st.push(p);
                p = p->left;
            }
            TreeNode* r = st.top();
            st.pop();
            ans.push_back(r->val);
            p = r->right;
        }
        return ans;
    }
```


### 字节对齐

 - 结构体变量中成员的偏移量必须是成员自身大小的整数倍
 - 结构体大小必须是最宽数据类型大小的整数倍。（嵌套的结构展开后的所有成员）
 - 嵌套的结构，展开后的结构体的第一个成员的偏移量应当是被展开的结构体中最大成员的整数倍。

### 指针变量所占字节

指针变量所占字节数是根据寻址空间决定宽度的：

 - 16 bit寻址空间为16 bit，所以指针变量宽度为2 Byte
 - 32 bit寻址空间为32 bit，所以指针变量宽度为4 Byte
 - 64 bit寻址空间为64 bit，所以指针变量宽度为8 Byte


